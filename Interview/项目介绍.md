
## 项目 endpoint
三个东西，path variable/request param/request body
订单续订服务（Order Renewal Service）:

续订一个订单：

HTTP Method: POST
URL: /orders/{orderId}/renew
Request Body: 可以包含续订订单需要的信息，例如：{"renewalPeriod": "1 year", "paymentMethod": "credit card"}
Output: 续订的订单的详细信息，可能是一个JSON对象，包含订单的所有信息。


实时报价服务（Real-time Quotation Service）:


获取在特定日期的产品报价：
HTTP Method: GET
URL: /products/{productId}/price/history
Request Parameters: date (例如 /products/price/history?date=2023-08-01 将返回所有在2023年8月1日更改的产品报价)
Output: 在特定日期更改的产品报价，可能是一个JSON数组，每个元素都包含产品ID，价格和价格的时间戳。

## dataflow
首先，实时报价服务通过kafka获取其他服务的数据，然后计算出实时报价。将实时报价存入redis，redis中只存过去1小时中所有产品的报价。同时，实时报价服务还把计算出来的报价传回kafka。报价历史服务会获取这些报价，存入bigtable，以供其他服务进行历史报价数据分析

您的思路有明确的数据流程和存储策略，我来为您提供一些反馈：

1. **实时报价服务 & Kafka**：使用Kafka获取其他服务的数据是合理的，特别是如果数据量大或需要实时数据流。Kafka的分布式特性和高吞吐量能够保证大量数据流畅地传输。

2. **存入Redis**：将计算后的实时报价存入Redis是明智的。Redis作为内存存储数据库可以提供非常快速的读写速度，这对于需要实时反馈的应用非常适用。限制Redis中数据的时间范围（例如最近1小时的数据）也是一个好策略，可以确保不会消耗过多的内存。

3. **数据回传到Kafka**：将计算后的实时报价回传到Kafka，供其他服务使用或分析，这是一个合理的策略，特别是当其他服务或系统需要这些数据时。

4. **报价历史服务 & Bigtable**：使用Bigtable存储历史报价数据是一个很好的决策。Bigtable作为一个高度可扩展的NoSQL数据库，非常适合存储大量的时间序列数据，如您的历史报价数据。

这种设计确保了数据的实时性和长期存储，且各部分之间的耦合度相对较低。不过还需要注意以下几点：

- **数据一致性**：确保Kafka、Redis和Bigtable之间的数据一致性。考虑到可能的失败，需要有策略来处理失败的消息或未能正确写入数据库的数据。

- **Redis的数据淘汰策略**：考虑使用Redis的TTL（Time-To-Live）特性来自动清除过期的数据。

- **资源监控和警报**：确保对所有组件（特别是Redis，由于其数据是在内存中的）进行资源使用和性能的监控，设置警报以防出现资源耗尽或其他问题。

总的来说，您的思路是合理和稳固的。
## Exception:
在设计微服务架构的系统时，使用定制的异常（Customized Exceptions）可以帮助我们更好地处理错误情况，并向用户和其他服务提供有用的错误信息。以下是一些可能的定制异常：

1. **OrderNotFoundException**：当试图查找或操作一个不存在的订单时，可以抛出这个异常。这个异常可以包含一个订单ID，用来标识找不到的订单。

2. **InsufficientInventoryException**：当库存不足以完成某个操作（如创建订单或续订订单）时，可以抛出这个异常。这个异常可以包含产品ID和所需的库存量。

3. **InvalidContractException**：当试图创建或修改一个不合法的合同（如合同日期无效或合同文本缺失）时，可以抛出这个异常。这个异常可以包含一个错误消息，描述了为什么合同是无效的。

4. **CustomerNotFoundException**：当试图查找或操作一个不存在的客户时，可以抛出这个异常。这个异常可以包含一个客户ID，用来标识找不到的客户。

5. **PriceNotFoundException**：当试图查找一个不存在的价格时，可以抛出这个异常。这个异常可以包含一个产品ID，用来标识找不到的价格。

6. **OrderRenewalException**：当订单续订失败时（如由于库存不足或支付失败），可以抛出这个异常。这个异常可以包含一个订单ID和一个错误消息，描述了为什么订单不能续订。

7. **ServiceCommunicationException**：当一个服务尝试与另一个服务通信，但通信失败时（如由于网络错误或服务不可用），可以抛出这个异常。这个异常可以包含一个错误消息，描述了通信失败的原因。

这些定制异常都应该继承自Java的RuntimeException或Exception类，这样它们可以被Spring的异常处理机制捕获，并被转换为适当的HTTP响应。


## 服务和数据库
关于数据库的选择，这个很大程度上取决于每个服务的具体需求。一般来说，如果服务需要进行复杂的查询，或者需要处理具有明确定义关系的数据，那么关系型数据库（如MySQL或PostgreSQL）可能是一个好选择。如果服务需要处理大量的非结构化数据，或者需要进行快速的读/写操作，那么NoSQL数据库（如MongoDB或Cassandra）可能更适合。

根据订单与合同系统，以下是可能的数据库配置：

1. **订单服务（Order Service）**：由于订单数据通常具有明确的结构，并且可能需要进行如按日期或用户查询等复杂查询，所以**关系型数据库**是一个好选择。

2. **库存服务（Inventory Service）**：**库存服务通常需要进行高速的读写操作，所以NoSQL数据库**可能是一个好选择。但如果库存信息与其他数据（如产品或供应商）有明确的关系，那么关系型数据库也可能是一个好选择。

3. **客户服务（Customer Service）**：由于客户数据通常具有明确的结构，比如客户和订单的关系，所以**关系型数据库**是一个好选择。

4. **合同服务（Contract Service）**：合同可能包含大量的非结构化数据，比如合同文本或附件，所以NoSQL数据库可能是一个好选择。对于合同的附件，我们还可以考虑使用像**AWS S3**这样的对象存储服务。

5. **订单续订服务（Order Renewal Service）和实时报价服务（Real-time Quotation Service）**：这些服务主要是处理业务逻辑，不太可能直接处理大量的数据。它们会与其他服务（和那些服务的数据库）进行通信来获取所需的数据。所以，它们可能不需要自己的数据库，或者只需要一个轻量级的数据库来存储一些状态或配置数据。

以上只是一种可能的配置，实际的配置可能会根据具体的业务需求和技术要求来进行调整。同时，我们也需要考虑数据库的性能、可扩展性、可用性等因素。


## GPT 提问
Suppose you are a java developer in Cisco Systems' Order and Quote team for Cisco Commercial Workspace. You are now taking an interview for a new senior java developer role. How would you answer the question:

Suppose you are a java developer in Cisco Systems' Order and Quote team for Cisco Commercial Workspace. You have  been working on the new order and contract system in past one and a half years. The new systems is based on Spring boot and Microservice architecture. 
You have developed some key features like real-time order renew and quote update. Could 
you tell any endpoints you developed?

## Cisco项目难点：



The biggest challenge was to manage high-volume, real-time data exchange among microservices in our Order and Contract system. Given the huge data volume, we first decided to use Kafka message queue to handle the communication messages among the service applications. It a event-driven tool and it can handle a lot of data but it still cannot satisfy our requirement on low latency at the first time.

To address this issue, I optimized the Kafka settings for batch size and commit latency, and adopted more efficient data serialization format instead of using Json we used Protobuf. Furthermore, I implemented database sharding to distribute data across multiple instances as well as adding more service instances, reducing pressure on a single server. And make messages being produced more quickly. Lastly, we conducted performance monitoring using Grafana which helped us identify and solve bottlenecks in time.


## cisco项目介绍

 I am working for the new order and contract system of Cisco Commercial Workspace. We built up a highly scalable and flexible system that can provide functionalities like order management , contract management, quote update and analysis with a fast response. This system is mainly built on spring boot and Oracle. Some of the modules like the quote analysis part are newly designed, which are with low latency and can improve the user experiences a lot. Other parts are migrated from the legacy monolithic system to the current microservices system using spring cloud and gcp. This part contains the main functionality of the system like order management and contract management, with a very high throughput, including support of real-time order update, efficient order query and so on.

### cisco贡献介绍
As a backend developer in our new order and contract system, I designed and implemented some key features including real-time order renew module and quote update module with spring boot, which can provide fast response to the users about any slight change about the order and quote among huge requests. I am also responsible for the migration of our legacy monolithic system into a cloud-based microservices system. In this process, I decomposed some  complex business logic into independent services, and deployed them  on to amazon web service. I also collaborate with team members to establish best practice for code quality and optimize the performance of the system. Finally we build up a new flexible and scalable system with high efficiency and low latency.

### Cisco Responsibility:

I am in charge of developing the quotation related modules with spring boot. This includes the real-time quote update, quote trend tracking, quote strategy adjustment and so on. I also collaborate with team members to build up a reliable and scalable micro services system with spring cloud and amazon web services. I Performed CI/CD pipeline process for the application using Jenkins, and use junit and mockito to conduct unit test and inter test to ensure the code quality and optimize the system.  I Engaged in the full Software Development Life Cycle work with team members and manager in Agile methodology.

## ATT 项目介绍
ATT 0ct. 2021 - March 2022
Our team specializes in delivering comprehensive network solutions and products to businesses. As a Java developer, my role involved designing and constructing an end-to-end application system the empowered enterprises with robust network management, configuration, and troubleshooting functionalities using Java, Spring and React. Additionally, I streamlined the software development and deployment processes by implementing DevOps practices, including Docker and Jenkins, enabling seamless continuous integration and delivery.


### 项目描述：
 In AT&T I developed an end-to-end platform centered around providing robust network solutions to companies. The core of this application is its Spring Boot backend, designed to efficiently store both enterprise information and network status data. This backend system includes crucial components like real-time network monitoring module, and configuration management module, which streamlines network adjustments, ensuring both security and stability. On the front-end side, I crafted several components with React to enhance the user experience. These components simplify the solution search process and offer a lucid view of network equipment statuses, making network oversight more straightforward.

## Cisco难点 follow up
**问题：你能详细说明如何优化Kafka的批处理大小和提交延迟吗？**
回答：我根据我们的系统负载和性能需求进行了一些实验，通过调整Kafka配置中的batch.size和linger.ms参数来优化性能。batch.size决定了可以一起发送的最大消息数量，而linger.ms决定了生产者在发送消息之前可以等待更多消息加入批处理的时间。通过调整这两个参数，我找到了我们的系统的最优设置。

**问题：你是如何进行数据库分片的？使用了什么工具或者方法？**
回答：我使用了垂直分片和水平分片两种策略。垂直分片是按功能模块将表分布在不同的数据库实例中，而水平分片是将一个表中的数据分布在多个数据库实例中。在技术上，我使用了一些数据库中间件来实现分片，例如ShardingSphere，它提供了丰富的分片策略，并且支持分片事务。

#### 数据库分片
垂直分片（Vertical Partitioning）：在垂直分片中，我们根据业务关系将数据库中的表分为不同的组，然后将每个组放入一个单独的数据库服务器中。这种方法可以降低锁的竞争，并且可以将不同的工作负载分配到专门的服务器上。然而，垂直分片可能需要对应用程序进行显著的修改，因为数据现在分布在多个数据库中。

例如，如果一个电商数据库有用户、订单和商品三个表。在垂直分片中，我们可能将用户表放在一个数据库服务器上，将订单表和商品表放在另一个数据库服务器上。

水平分片（Horizontal Partitioning）：水平分片是将一个表中的行分配到多个数据库中。每个数据库包含表的一个子集，但表的结构在所有数据库中都是相同的。这可以使大型表的查询更快，并且可以在多个服务器上分配负载。

例如，如果我们有一个包含所有订单的大表，我们可以将订单按照订单ID进行水平分片，例如，将订单ID为奇数的订单放在一个数据库服务器上，将订单ID为偶数的订单放在另一个数据库服务器上。

**问题：你怎样确保在高负载下系统的稳定性和性能？**
回答：我使用了一系列的策略来确保系统的稳定性和性能。首先，我对数据库和消息队列进行了优化和分片，减轻了单个实例的压力。其次，我引入了缓存机制，减轻了数据库的负载并加速了数据访问。我还使用了负载均衡器，防止了服务过载。最后，我引入了监控工具来实时监控系统性能，一旦发现性能问题，我会立即进行优化。通过这些策略，我确保了系统在高负载下的稳定性和性能

在服务间使用Kafka消息队列和protobuf进行通信，你可以按照以下步骤进行编写代码：

1. **定义protobuf消息格式**：与前述步骤相同，首先需要在`.proto`文件中定义你的数据结构。

2. **生成Java类**：使用protobuf编译器生成对应的Java类。

3. **序列化与反序列化**：使用生成的Java类中的方法将数据对象转换为protobuf格式，或者将protobuf格式的数据转换为数据对象。具体来说，如果你的服务需要发送一条消息，你可以创建一个数据对象，然后调用`toByteArray()`方法将其转换为字节数组，然后将字节数组发送到Kafka。如果你的服务需要接收一条消息，你可以从Kafka中获取字节数组，然后调用`parseFrom(byte[] data)`方法将其转换为数据对象。

### 具体实现
对于Spring Boot应用程序，你可能会使用Spring Kafka库，该库提供了`KafkaTemplate`类，你可以使用这个类来发送和接收消息。`KafkaTemplate`类的`send()`方法可以用于发送消息，`@KafkaListener`注解可以用于定义接收消息的方法。

服务在处理完请求并生成了结果后，将结果转换为protobuf格式，并发送到Kafka。然后，Controller监听Kafka的相关主题，获取到结果，将其从protobuf格式转换为JSON格式，然后返回给前端。

请注意，你还需要在Kafka配置中指定正确的序列化器和反序列化器。对于protobuf数据，你可以使用Kafka的`ByteArraySerializer`和`ByteArrayDeserializer`。

以下是一个简单的示例，假设`OrderProto.Order`是从`.proto`文件生成的Java类：

```java
// Service
@Autowired
private KafkaTemplate<String, byte[]> kafkaTemplate;

public void processOrder(OrderProto.Order order) {
    // Process the order...
    
    // Convert the result to protobuf format and send it to Kafka
    byte[] resultData = result.toByteArray();
    kafkaTemplate.send("resultTopic", resultData);
}

// Controller
@KafkaListener(topics = "resultTopic")
public void receiveResult(byte[] data) {
    // Convert the protobuf data to JSON and return it to the frontend
    OrderProto.Order result = OrderProto.Order.parseFrom(data);
    // Convert the result to JSON and return it...
}
```

这只是一个基本示例，实际代码可能需要根据你的需求和你的系统架构进行修改。希望这个答案可以帮助你理解服务间如何使用protobuf进行通信，以及如何将结果返回给Controller。


## 项目业务
订单报价系统：
https://www.cnblogs.com/xcj26/p/14103370.html

https://zhuanlan.zhihu.com/p/446280035
https://www.dejia.co/
https://www.woshipm.com/pd/2967656.html

注意cisco的产品主要是路由器，交换机，iot设备，AI ML算法加持
https://www.cisco.com/c/en/us/products/index.html#~products-by-technology



### order renew

在订单管理系统中，"order renew"（订单续订）业务场景通常发生在以下情况下：

订购周期到期：当订单的订购周期（通常是订购服务或产品的有效期）即将到期时，客户可能希望继续使用该服务或产品。他们可以选择进行订单续订，以延长订购周期并保持连续的服务。

自动续订选项：有些服务或产品提供了自动续订选项。如果客户启用了自动续订功能，系统会在订单到期前自动进行续订操作，以确保服务或产品的持续供应。

定期续订计划：针对一些定期订购模式（如订阅服务），客户可能会参与定期续订计划。在这种情况下，订单续订是按照预定的时间表自动执行的，并且客户可以在需要时进行更改或取消续订。

总之，"order renew"（订单续订）业务场景涉及到客户希望在订单到期后继续使用服务或产品，并通过执行续订操作来延长订单的有效期。这样可以确保客户在需要的时间内持续享受服务或产品的好处。

### quote update

"quote update"（报价更新）业务场景通常发生在以下情况下：

客户需求变化：当客户对报价中的某些细节或要求有变更时，他们可能需要更新现有的报价。这可能涉及修改产品数量、更改定价策略、添加或删除特定产品或服务等。

价格谈判：在商业谈判过程中，买方和卖方之间可能发生价格和条件的讨论。如果双方就某些条款达成共识，报价可能需要进行更新以反映新的商议结果。

产品可用性变动：如果在报价过程中某些产品或服务的可用性发生变化，例如暂时缺货、新产品上市等，报价需要进行更新以反映这些变动。

报价错误修正：如果在创建报价时发现错误或遗漏，需要进行报价更新以纠正这些错误或补充缺失的信息。

综上所述，"quote update"（报价更新）业务场景涉及到在报价过程中需要修改、调整或补充报价信息的情况。这可以是由于客户需求变化、价格谈判、产品可用性变动或报价错误修正等原因引起的需求。

## cisco 业务
Yes, Cisco is a well-known multinational technology company that offers a wide range of products and services, including networking equipment, security solutions, collaboration tools, and more. Cisco's order and quote team is responsible for managing the order and quote process for customers, ensuring smooth transactions and accurate pricing.

The order and quote team at Cisco typically handles the following responsibilities:

1. Order Management: The team manages the end-to-end order processing, starting from receiving customer orders to ensuring timely delivery. They coordinate with various internal departments, including sales, logistics, and finance, to facilitate a seamless order fulfillment process.

2. Pricing and Quotes: The team is responsible for generating accurate quotes for customers based on their requirements, product configurations, and pricing guidelines. They ensure that pricing information is up to date, and any discounts or promotions are properly applied.

3. Contract and Agreement Management: The team handles contract and agreement administration, ensuring that customer contracts are properly recorded, updated, and aligned with the agreed terms and conditions. They may also assist in negotiating and finalizing contracts with customers.

4. Customer Support: The order and quote team provides support to customers regarding order status, pricing inquiries, and other related queries. They address customer concerns, resolve issues, and maintain strong communication throughout the order process.

5. Process Improvement: The team continuously looks for opportunities to improve order management processes, streamline workflows, and enhance customer satisfaction. They collaborate with cross-functional teams to identify areas of improvement and implement efficient practices.

6. Compliance and Documentation: The team ensures adherence to regulatory requirements, company policies, and legal standards related to order and quote processes. They maintain accurate records, documentation, and audit trails for compliance purposes.

Cisco's order and quote team plays a crucial role in delivering a positive customer experience by effectively managing the order fulfillment process, ensuring accurate pricing, and providing timely support. Their efforts contribute to the smooth functioning of Cisco's business operations and the satisfaction of their customers.


## 简历重点

可以把docker/hibernate放到第二个经历中去。
### 原本的list:
1. Transformed the order quoting system from a monolithic application into a Microservices architecture with Spring Boot and Spring Cloud using Agile methodology, enabling enhanced scalability in the delivery of services.
2. Developed backend applications for order management module following MVC design pattern, connecting to AWS-hosted MySQL database with Hibernate and JPA, and enabling service communication through Kafka.
3. Utilized Mockito and JUnit for effective testing, Docker for efficient containerization, and Jenkins for seamless CI/CD pipelines, ensuring code quality and accelerating software development and deployment.

1. Pioneered the implementation of real-time quoting service within the Order and Quote system, enabling instantaneous and accurate price calculations for customers.
2. Collaborated closely with cross-functional teams, including sales and marketing, to understand customer requirements and integrate the real-time quoting service seamlessly into the existing workflow. 


1做了这个服务，达成了什么效果
2kafka做了服务通信，提高速度降低延迟。突出特点，大量数据。提
3和其他队伍合作，
4 test
5 pipeline



### 新的list
当然，以下是基于你的需求，我为你准备的一些简历bullet points：

- Spearheaded the design and implementation of a Kafka-based real-time pricing system, capable of handling 5,000 messages per second, providing real-time and accurate product prices to users.
  - 领导设计并实现了基于Kafka的实时报价系统，该系统能够处理每秒5,000条消息，为用户提供实时、准确的产品报价。

- Optimized system performance and response times by implementing data preprocessing and caching strategies, reducing the average quotation update latency by 50%.
  - 通过实施数据预处理和缓存策略，优化了系统性能和响应时间，将平均报价更新延迟减少了50%。

- Integrated multiple data sources including product inventory, trade history, market competition, and customer behavior for real-time analysis, supporting real-time pricing decisions.
  - 对接了多个数据源，包括产品库存、交易历史、市场竞争信息、客户行为等，进行实时分析，以支持实时报价决策。

- Ensured high availability and scalability of the real-time pricing system in the face of large volumes of data, by utilizing Kafka and a microservice architecture.
  - 通过使用Kafka和微服务架构，确保了实时报价系统在大数据量下的高可用性和可扩展性。

- Utilized Kafka's message replay feature to provide the capability of reviewing and analyzing historical pricing data, leading to data-driven business decisions that increased sales by 30%.
  - 利用Kafka的消息重播功能，提供了回溯和分析历史报价数据的能力，从而引导数据驱动的业务决策，增加了30%的销售额。

以上就是你的简历bullet points，它们突出了你的技术能力、解决问题的策略以及你的工作成果对业务产生的影响。



## 关于实时报价的计算：
### 问题：
关于：
Integrated multiple data sources including product inventory, trade history, market competition, and customer behavior for real-time analysis, supporting real-time pricing decisions.

让你来设计这个需要高并发低延迟的系统，你觉得下列那种方案更适合？还是这些方案都不好？

1. product inventory service, trade history service, market competition service等，在服务中就计算出一些结果，并且直接把这些中间结果给Kafka，然后real-time quotation service直接拿到处理后的结果进行简单计算就得到实时报价
2. product inventory service, trade history service, market competition service等，将原始数据传入kafka，通过kafka stream计算出中间结果，然后real-time quotation service直接拿到处理后的结果进行简单计算就得到实时报价
3.product inventory service, trade history service, market competition service等，将原始数据传入kafka，然后real-time quotation service拿到数据后，再进行相对复杂的计算，并最后返回实时报价
### 分析
你提出的三种方案都有其适用的场景，它们各有优劣，选择哪种方案主要取决于具体的业务需求、系统复杂性、可维护性以及系统性能要求。以下是对这三种方案的评价：

1这种方案最简单，由每个服务处理自己的数据并计算出中间结果，然后把这些中间结果传给Kafka。优点是每个服务的计算负担较轻，整个系统的复杂性较低。但是，如果需要改变中间结果的计算方式，或者添加新的服务，可能需要修改多个服务的代码，这在维护上可能会带来挑战。

2这种方案使用了Kafka Stream来进行实时计算，这是Kafka的一个重要特性。优点是可以在一个中心地点进行所有的计算，使得系统的逻辑更加集中，更容易理解和维护。而且，Kafka Stream本身就是设计用来处理大数据流的，所以性能上也能满足要求。但是，这种方案的复杂性和技术难度较高，需要对Kafka Stream有深入的了解。

3这种方案是最直接的，每个服务只处理和传递原始数据，然后由real-time quotation service来进行全部的计算。优点是系统的逻辑非常清晰，每个服务的责任分工明确。但是，这种方案对real-time quotation service的性能要求非常高，因为所有的计算都需要在这个服务中进行。如果数据量非常大，可能需要使用一些高性能的计算技术，例如并行计算。

综上所述，我会倾向于选择方案2或方案3。具体选择哪一个，取决于你对Kafka Stream的熟悉程度，以及real-time quotation service能否处理大量的计算任务。如果你对Kafka Stream很熟悉，或者有资源来学习它，那么我会推荐方案2。否则，我会推荐方案3，并确保real-time quotation service有足够的性能来处理大量的计算任务。


在真实的业务开发场景中，我会倾向于选择第一种方案。原因如下：

1. 计算分散：将复杂的计算工作分散到各个服务中去，这样一方面可以避免创建一个超级大的、计算压力极大的服务，降低了服务故障的风险；另一方面，当某个计算逻辑发生变更时，只需修改对应的服务，不会影响到其他服务。

2. 简单易维护：在每个服务内部完成计算，避免了大量的数据在服务之间传递，降低了系统的复杂度。同时，由于各个服务的功能更加单一和清晰，也更便于理解和维护。

3. 解耦合：每个服务只需要关注自己的业务逻辑，不需要关心其他服务的实现，这样降低了服务之间的依赖，提高了系统的灵活性和扩展性。

但是需要注意的是，这种方案也有它的缺点，即需要在服务之间同步数据，这可能会引入一些复杂性。同时，由于数据是在各个服务中预处理后再传递的，如果需要修改预处理逻辑，可能需要修改多个服务的代码。因此，选择这个方案时，需要确保良好的服务设计和编程实践，例如确保服务的单一职责，避免服务间的紧耦合，以及确保良好的数据管理和同步策略。


举例：比如市场情况的例子，可以让market competition service先计算最近一周这个产品的均价和中位数，再传给报价系统。



### 关于消息重放和历史价格相关计算
Utilized Kafka's message replay feature to provide the capability of reviewing and analyzing historical pricing data, leading to data-driven business decisions that increased sales by 30%.

你可以从原理和代码角度讲讲这个怎么做到吗？代码请模拟上面这句话中的场景

Kafka 的消息重放特性能够让消费者重新读取旧的消息。这在很多情况下都很有用，例如在你的情况中，你想要回顾和分析历史的定价数据。

**原理：**

在 Kafka 中，消费者从 Kafka 的主题（Topics）读取消息。每个消息在它所在的分区（Partition）中都有一个唯一的编号，称为 offset。消费者读取消息的过程就是获取主题中一个或多个分区的消息，同时追踪每个分区最后读取的消息的 offset。当消费者重新启动或者需要从旧的位置开始读取时，它可以从特定的 offset 开始读取。

这意味着，如果你想要重放历史的定价数据，你可以记录你首次读取每个消息的 offset。然后，当你需要重放数据时，你可以让消费者从这些记录的 offset 开始读取。

**代码：**

以下是一个简单的示例，展示了如何使用 Kafka 的 Java 客户端库来回顾历史定价数据。请注意这只是一个基础示例，实际使用中可能需要考虑更多的细节，如错误处理、安全性等。

```java
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.Collections;
import java.util.Properties;

public class ReplayConsumer {

    private KafkaConsumer<String, String> consumer;

    public ReplayConsumer(String bootstrapServers, String groupId) {
        Properties props = new Properties();
        props.put("bootstrap.servers", bootstrapServers);
        props.put("group.id", groupId);
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        consumer = new KafkaConsumer<>(props);
    }

    public void replayMessages(String topic, long offset) {
        // 订阅主题
        consumer.subscribe(Collections.singletonList(topic));
        // 重置指定主题分区的 offset
        consumer.seekToBeginning(consumer.assignment());
        consumer.assignment().forEach(topicPartition -> consumer.seek(topicPartition, offset));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(100);
            for (ConsumerRecord<String, String> record : records) {
                System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
                // TODO: 实现历史定价数据的处理逻辑
            }
        }
    }
}
```
你可以使用 `replayMessages(topic, offset)` 方法来重放指定 offset 之后的消息。

需要注意的是，这个示例假设所有分区从相同的 offset 开始重放。如果每个分区的 offset 不同，你需要为每个分区指定不同的 offset。此外，这个示例在重放完消息后会一直运行。如果你只想重放一部分消息，你可能需要提供一个方式来停止消费者。



## 可能会被问到的问题：
### kafka vs rabbitmq
#### 理论：
RabbitMQ 和 Kafka 都是非常流行的消息队列解决方案，但它们是为不同的应用场景和需求设计的。以下是关于何时选择它们的一些建议：

##### 1. RabbitMQ：

- **短暂的消息生命周期**: 如果你需要一个系统，在其中消息一旦被消费就被删除，RabbitMQ 是一个很好的选择。
  
- **复杂的路由**: RabbitMQ 提供了丰富的消息路由功能，如 direct, topic, headers 和 fanout exchanges。如果你的应用需要复杂的消息分发逻辑，RabbitMQ 可能是更好的选择。
  
- **优先级队列**: RabbitMQ 支持优先级队列，允许一些消息优先于其他消息被处理。

- **延迟队列**: 通过插件或消息TTL特性，RabbitMQ可以实现消息的延时投递。

- **更多的语言支持**: RabbitMQ 提供了多种编程语言的客户端，这使得它与多种应用程序和环境兼容。

##### 2. Kafka：

- **长时间的消息保留**: Kafka 设计为可以存储大量的数据，并保留这些数据很长时间（例如，数周、数月或永久），这使得它非常适合日志存储或事件溯源等应用场景。

- **高吞吐量**: Kafka 旨在处理大量数据的读写操作，并且它在分布式环境中可以水平扩展，这使得它非常适合大数据处理场景。

- **分布式和高可用性**: Kafka 是为分布式环境设计的，它可以跨多个节点/服务器进行部署，增加了可用性和容错性。

- **流处理**: Kafka Streams API 允许你在数据流入 Kafka 的同时进行数据处理。

- **复制和容错**: Kafka 的数据可以在多个副本中进行复制，增加了数据的持久性和容错能力。

##### 总结:

- 如果你的需求是关于高效、可靠的消息投递，且需要复杂的消息路由、延迟队列或优先级队列，RabbitMQ 可能更合适。
  
- 如果你的应用需要高吞吐量、长时间的消息存储、分布式处理或流处理，Kafka 可能是更好的选择。

当然，这些只是一些建议，最终的决策应根据你的具体需求和架构考虑进行。
#### 场景
当然，我可以提供一些真实业务场景的例子来帮助你理解 RabbitMQ 和 Kafka 在何时被选为解决方案：

##### RabbitMQ的典型使用场景：

1. **电商系统中的订单处理**：当用户下单时，为了不阻塞用户，订单处理任务可以被发送到RabbitMQ，后台服务异步处理订单，包括库存检查、支付、发货等。

2. **通知系统**：如果你的应用需要给用户发送大量的电子邮件、短信或其他通知，你可以使用 RabbitMQ 来异步地处理这些通知。

3. **日志收集**：虽然 Kafka 在这方面更受欢迎，但 RabbitMQ 也可以被用于收集微服务的日志并将其发送到集中的日志系统中。

4. **任务队列**：例如，一个web应用接受用户上传的图片并需要处理（裁剪、压缩、加水印等），这些任务可以被发送到RabbitMQ，后台工作者可以逐一处理它们。

##### Kafka的典型使用场景：

1. **日志流系统**：例如，大型网站使用 Kafka 收集其庞大的用户活动日志，然后将这些数据流式处理或批处理到数据湖或数据仓库中。

2. **监控数据**：对于大型的分布式系统，Kafka 可以被用来收集系统的各种指标，然后供实时监控工具或者报警系统使用。

3. **实时分析**：如金融领域中，根据实时交易数据进行股票价格分析和预测。

4. **事件溯源**：在微服务架构中，服务之间的每一个操作可以被视为一个事件。这些事件可以被发送到 Kafka，为后续的分析和审计提供详细的历史数据。

5. **数据同步**：例如，在微服务架构中，当一个服务的数据发生变化时，可能需要通知其他服务。Kafka 可以作为中间层，确保数据在各个服务之间同步。

在选择 RabbitMQ 还是 Kafka 时，要根据具体的应用需求和预期的工作负载来做决策。但无论选择哪个，两者都是非常强大的工具，可以在正确的场景下发挥出它们的最大优势。

#### 为什么real-time quotation 用kafka

1. before telling you about technical reason. I need to firstly point out that Coordinate with other services like product inventory service. They pass data to kafka mq so I need get……
2. rmq: synchronous while kafka is asyn and event-driven; is able to handle high throughput situation; and more suitable for distributed system(easy to extend brokers horizontally)
3. kafka better in durability. Msg in rmq, once consumed it is deleted, but msg in kafka remains and kafka do support message replay. Convenient for other functionalities, like historical data analysis. 


Kafka 和 RabbitMQ 都是优秀的消息系统，但在设计初衷和一些核心特性上有所不同，这使它们在某些使用场景下有明显的优势。对于实时分析来说，以下是一些原因，说明为什么 Kafka 更受欢迎：

1. **数据存储与回放**：Kafka 设计为一个持久的日志系统，可以存储大量的数据并允许数据回放。这意味着，即使数据已经被消费，也可以再次读取，这在实时分析中非常有用，尤其是当需要重新处理或分析历史数据时。而 RabbitMQ 主要设计为消息队列，一旦消息被消费，它就从队列中被删除。

2. **吞吐量**：Kafka 设计用于高吞吐量的场景，能够处理每秒数百万的消息。其分区的设计允许并行读写，这使得 Kafka 非常适合大数据实时处理。

3. **分布式与伸缩性**：Kafka 是为分布式而生，可以水平扩展，只需增加更多的节点即可。这意味着当数据流量增加时，Kafka 可以轻松地扩展以处理更多的数据。

4. **流处理**：Kafka 提供了 Kafka Streams API，这是一个流处理库，允许直接在 Kafka 上进行流式计算，而无需引入其他框架。

5. **持续性和可靠性**：Kafka 的分布式和副本特性使其非常持久和可靠。即使多个节点出现故障，只要有足够的副本，数据仍然是安全的。

6. **集成生态系统**：许多大数据工具（如 Apache Spark、Apache Flink、Apache Storm）都与 Kafka 有很好的集成，这使得它在实时分析中更具吸引力。

7. **多消费者模型**：在 Kafka 中，同一份数据可以被多个消费者组并行消费，不同的消费者可以有不同的处理速度。这在实时分析中非常有用，尤其是当有多个分析任务需要读取同一份数据时。

RabbitMQ 更适合用作实时消息队列，确保消息的传递和处理，而 Kafka 更适合数据流处理和实时分析。所以，在实时分析场景中，Kafka 往往是首选。

## 其他简历
原本：
Designed a online management system of the education platform, using Java and Spring MVC.
Designed MySQL schema for users, events etc. and used C3P0 connection pool and MyBatis to handle queries.
Implemented RESTful APIs for user profile, course event and other modules with Spring MVC.
Applied Microservices Architecture to decouple services and thus improve stability and flexible extendibility.
Added Eureka servers for service registration and discovery with Spring Cloud and applied Hystrix to handle incidents of fallback, break and high concurrency.

需要保留的点：
1 mysql schema
2 mybatis/c3p0
3 restful api
4 deploy microservice - aws
5 docker /  cicd 