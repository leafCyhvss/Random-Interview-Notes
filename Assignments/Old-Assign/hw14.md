1. Document the microservice architeture and components/tools/dependencies

   Microservice architecture is an architectural style that structures an application as a collection of loosely coupled and independently deployable services. Each service represents a specific business capability and can be developed, deployed, and scaled independently.

   1. API Gateway:
      - API Gateway acts as the entry point for all client requests and provides a single, unified interface to the microservices.
      - It handles request routing, authentication, authorization, rate limiting, and can also perform other cross-cutting concerns like logging and monitoring.
      - Popular API Gateway solutions include Netflix Zuul, Spring Cloud Gateway, and Kong.
   2. Eureka:
      - Eureka is a service registry and discovery server that allows microservices to register themselves and discover other services in the ecosystem.
      - It enables dynamic service discovery and load balancing by maintaining a registry of all available services and their network locations.
      - Eureka is part of Netflix OSS and works well with other Netflix components like Ribbon and Hystrix.
   3. Load Balancing (Ribbon):
      - Ribbon is a client-side load balancing library that works in conjunction with service discovery to distribute client requests across multiple instances of a service.
      - It automatically handles load balancing, failover, and fault tolerance by choosing an available instance of a service for each request.
      - Ribbon integrates well with Eureka and other service discovery mechanisms.
   4. Circuit Breaker (Hystrix):
      - Hystrix is a fault tolerance library that helps in building resilient microservices by handling failures and latency issues.
      - It implements the circuit breaker pattern to prevent cascading failures and provides fallback mechanisms for handling errors.
      - Hystrix monitors the health of services and can automatically open the circuit (stop sending requests) to a failing service, thereby preventing further degradation.
      - It also supports metrics, monitoring, and configurable timeouts.
   5. Config Server:
      - Config Server is responsible for managing the externalized configuration for microservices.
      - It provides a central location for storing configuration properties, which can be accessed by microservices at runtime.
      - Microservices can retrieve their configuration from the Config Server during startup, allowing for dynamic and centralized configuration management.
      - Spring Cloud Config is a popular choice for implementing a Config Server.
   6. Kafka:
      - Kafka is a distributed streaming platform that provides publish-subscribe messaging and real-time event streaming capabilities.
      - It allows microservices to communicate asynchronously and decoupled, enabling event-driven architectures.
      - Microservices can publish messages to Kafka topics, and other services can consume these messages for processing.
      - Kafka provides fault-tolerant and scalable message processing and is commonly used for event sourcing, logging, and data integration scenarios.
   7. Docker:
      - Docker is a popular containerization platform that allows applications to be packaged into lightweight, isolated containers.
      - Containers provide a consistent runtime environment, making it easier to deploy and manage microservices across different environments.
      - Docker enables easy scalability, versioning, and portability of microservices, making them independent of the underlying infrastructure.
      - Docker also facilitates the use of container orchestration platforms like Kubernetes for managing and scaling microservices.

2. What are Resilience patterns? What is circuit breaker?

   Resilience patterns are design patterns and strategies used to build robust and resilient software systems. They aim to handle and recover from failures, mitigate faults, and ensure system stability and availability in the face of unpredictable and adverse conditions.

   A circuit breaker is a design pattern used to handle and prevent cascading failures in distributed systems. It acts as a safety mechanism that monitors the state of a service and automatically trips open when failures exceed a certain threshold. This helps to prevent further requests to the failing service, allowing it time to recover. The circuit breaker can then be reset to allow traffic flow again.

3. Read this article, then list the important questions, then write your answers

​	a. https://www.interviewbit.com/microservices-interview-questions/#main-features-of-microservices

3.1What are the benefits and drawbacks of Microservices?

**Benefits:** 

- Self-contained, and independent deployment module. 
- Independently managed services.  
- In order to improve performance, the demand service can be deployed on multiple servers.  
- It is easier to test and has fewer dependencies.  
- A greater degree of scalability and agility.  
- Simplicity in debugging & maintenance.  
- Better communication between developers and business users.  
- Development teams of a smaller size.

**Drawbacks:** 

- Due to the complexity of the architecture, testing and monitoring are more difficult.  

- Lacks the proper corporate culture for it to work.  

- Pre-planning is essential.  

- Complex development.  

- Requires a cultural shift.  

- Expensive compared to monoliths.  

- Security implications. 

- Maintaining the network is more difficult.  

  

3.2Explain how independent microservices communicate with each other.

Communication between microservices can take place through: 

- HTTP/REST with JSON or binary protocol for request-response 
- Websockets for streaming.  
- A broker or server program that uses advanced routing algorithms.  

RabbitMQ, Nats, Kafka, etc., can be used as message brokers; each is built to handle a particular message semantic. You can also use Backend as a Service like Space Cloud to automate your entire backend. 



5. how to do load balance in microservice? Write a long Summary by yourself.

​	a. https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/

​	b. https://www.fullstack.cafe/blog/load-balancing-interview-questions

Load balancing in a microservice architecture is crucial to ensure optimal performance, scalability, and reliability. It involves distributing incoming network traffic across multiple instances of a service to prevent any single component from being overwhelmed. Here are some common load balancing techniques used in microservices:

1. Round Robin: Requests are distributed evenly among available instances in a circular manner. It ensures that each instance gets a fair share of the traffic.

2. Least Connection: Traffic is routed to the server with the fewest active connections. This ensures that the load is evenly distributed based on the current load of each server.

3. Session Affinity/Sticky Sessions: Requests from the same client are consistently routed to the same server. This is useful when maintaining session state or when certain operations require continuity.

4. Load Balancer Algorithms: Advanced algorithms such as weighted round-robin, least response time, and IP hash can be used to consider factors like server capacity, response time, or client IP address.

5. Dynamic Load Balancing: Load balancers dynamically adjust the distribution of traffic based on real-time server health, performance, or availability metrics. This allows for efficient resource utilization and fault tolerance.

Implementing load balancing in a microservice architecture requires a combination of load balancing algorithms, infrastructure components (such as load balancer appliances or software), and service discovery mechanisms (like Eureka or Consul). It's important to choose the right load balancing strategy based on the specific requirements and characteristics of your microservices.

6. How to do service discovery?

   Service discovery is a critical component in a microservice architecture to locate and communicate with services dynamically. Here are some common approaches to implement service discovery:

   1. Client-Side Discovery: In this approach, each service instance registers itself with a service registry (e.g., Eureka, Consul) upon startup. When a client needs to communicate with a service, it queries the service registry to obtain the location (host and port) of an available instance. The client then directly communicates with the chosen instance.

   2. Server-Side Discovery: With this approach, a separate component called a load balancer or API gateway is responsible for service discovery. The load balancer or gateway acts as a single entry point for all client requests and forwards them to the appropriate service instance based on predefined routing rules. The load balancer or gateway maintains an internal registry of service instances and their locations.

   3. Service Mesh: Service mesh frameworks, like Istio or Linkerd, provide advanced service discovery capabilities. They work by injecting a sidecar proxy alongside each service instance, which intercepts and routes traffic between services. The service mesh infrastructure takes care of service discovery, traffic management, and other advanced features like circuit breaking and fault tolerance.

7. What are the major components of Kafka?
   Producer: Publishes data to Kafka topics.

   Consumer: Reads data from Kafka topics.

   Broker: Stores and manages the published data.

   Topic: Represents a specific stream of data.

   Partition: Divides a topic into separate logs for parallel processing and scalability.

   Offset: Unique identifier representing the position of a message within a partition.

   (ZooKeeper: Manages and coordinates the Kafka cluster by electing leaders, storing metadata, and maintaining cluster health.)

8. What do you mean by a Partition in Kafka?

   A partition is a unit of parallelism and scalability within a topic. It is a logical division of a topic's data log that allows messages to be distributed and processed in parallel across multiple brokers. Each partition is ordered and immutable, meaning that messages within a partition are stored in the order they are produced and cannot be modified once written. 

   Partitions enable horizontal scalability and fault tolerance by distributing the load across multiple brokers and allowing each broker to handle a subset of the topic's data. Additionally, partitions allow for efficient data retrieval and processing, as consumers can read from and process partitions independently and in parallel.

9. What do you mean by zookeeper in Kafka and what are its uses?

   In Kafka, ZooKeeper is a centralized coordination service that is used for maintaining and managing the Kafka cluster. It acts as a distributed synchronization and configuration service, providing a reliable and highly available environment for Kafka to operate.

   The main uses of ZooKeeper:

   1. Cluster Coordination: ZooKeeper helps in electing a leader among the Kafka brokers, maintaining the list of active brokers, and managing the state of the cluster.

   2. Topic and Partition Management: ZooKeeper tracks the metadata of topics and their partitions, including information about the number of partitions, replication factor, and the location of leaders for each partition.

   3. Consumer Group Coordination: ZooKeeper assists in managing consumer groups by keeping track of the offsets of consumed messages, ensuring fault tolerance and load balancing across consumer instances.

   4. Failover and Recovery: ZooKeeper provides the ability to handle failures and perform leader election in case of broker or replica failures.

   Overall, ZooKeeper plays a crucial role in the reliable and distributed functioning of Kafka by providing coordination, configuration management, and synchronization among the Kafka brokers and consumers.

10. Can we use Kafka without Zookeeper?

    Starting from version 0.10.0.0, Kafka introduced a new feature called the Kafka Controller, which allows Kafka to operate without the dependency on ZooKeeper for basic functioning. This feature is known as the "KRaft" mode.

    In KRaft mode, the Kafka Controller takes over the responsibilities that were previously handled by ZooKeeper, such as leader election and maintaining metadata. This allows Kafka to operate in a more streamlined and self-contained manner.

11. Explain the concept of Leader and Follower in Kafka.

    In Kafka, the concept of Leader and Follower pertains to the replication of data across multiple Kafka brokers. Each partition in Kafka is replicated across multiple brokers to provide fault tolerance and high availability.

    - Leader: The Leader is the primary replica for a partition. It is responsible for handling all read and write requests for that partition. Producers send messages to the Leader, and consumers fetch data from the Leader. The Leader maintains the in-sync replicas (ISRs) list, which consists of all the replicas that are up-to-date and in sync with the Leader.

    - Follower: The Followers are the replicas that replicate data from the Leader. They stay in sync with the Leader by continuously fetching and replicating the messages. Follower replicas serve as backups for the Leader and can take over as the Leader in case the current Leader fails. However, Followers do not serve read or write requests directly from clients.

    The Leader-Follower replication model ensures that even if the Leader fails, one of the Followers can take over quickly and continue serving requests without any interruption. This replication model provides fault tolerance and enables Kafka to handle high loads and provide high availability for data streaming.

12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?

    (1)

    Topic replication in Kafka is important for ensuring fault tolerance and high availability of data. Replication involves creating multiple copies of each topic's partitions across different brokers in a Kafka cluster. 

    The benefits of topic replication include:

    1. Fault tolerance: If a broker hosting a partition fails, the replicas of that partition on other brokers can take over and continue serving data. This ensures that data remains available even in the event of broker failures.

    2. High availability: With multiple replicas of a partition, Kafka can distribute the load and handle more concurrent read and write requests. Clients can fetch data from any replica, providing high availability and reducing the risk of service disruptions.

    (2)

    ISR stands for "In-Sync Replica." In Kafka, the ISR is a subset of replicas for a partition that are considered up-to-date and in sync with the leader replica. The ISR consists of replicas that are caught up with the leader's log and can effectively serve read requests. Kafka ensures that the leader replica remains in sync with the ISR by replicating data to all replicas in the ISR before acknowledging a write request. If a replica falls behind or becomes unavailable, it is removed from the ISR until it catches up or becomes available again.

    By maintaining the ISR, Kafka ensures that data durability and consistency are maintained. Clients can fetch data from replicas in the ISR with confidence, knowing that they are reading the most recent and consistent data. If a leader fails, one of the replicas from the ISR can be elected as the new leader, ensuring continuity of data availability and consistency.

13. What do you understand about a consumer group in Kafka?

    In Kafka, a consumer group is a group of consumers that work together to consume and process messages from one or more topics. Each consumer within a consumer group is assigned to a subset of partitions within the topic(s) it is consuming from. 

    The key points about consumer groups in Kafka are:

    1. Parallelism and Load Balancing: Consumer groups enable parallel processing of messages by distributing the partitions of a topic among the consumers in the group. Each consumer within the group exclusively reads from its assigned partitions, allowing for load balancing and increased throughput.

    2. Offset Management: Kafka keeps track of the offset, or the position of the last consumed message, for each consumer group. This allows consumers to resume from where they left off in case of failures or restarts.

    3. Scalability: Consumer groups allow for scaling the consumption of messages horizontally. By adding more consumers to a group, the overall processing capacity can be increased, providing higher throughput.

    4. Fault Tolerance: If a consumer within a group fails, Kafka automatically rebalances the partitions and reassigns them to the remaining consumers, ensuring uninterrupted processing and fault tolerance.

    Consumer groups are particularly useful in scenarios where you need to process messages in parallel or distribute the workload across multiple consumers. They enable scalable and fault-tolerant processing of messages in Kafka.

14. How do you start a Kafka server?

    ```shell
    docker pull confluentinc/cp-kafka
    docker run -d --name kafka -p 9092:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 confluentinc/cp-kafka
    docker logs kafka
    ```

    Start zookeeper first than kafka.

15. Tell me about some of the real-world usages of Apache Kafka.

    1. Internet of Things (IoT): Kafka is used in IoT environments to handle large volumes of data generated by connected devices. For instance, Cisco uses Kafka to process and analyze sensor data from various IoT devices for real-time insights and decision-making.
    2. Real-time Streaming: Kafka is extensively used for real-time data streaming in large-scale platforms. For example, LinkedIn uses Kafka for activity tracking, monitoring, and event data processing in their social networking platform.
    3. Log Aggregation: Kafka can collect and centralize log data from different systems, making it easier for companies to analyze and troubleshoot issues. Uber utilizes Kafka to handle millions of log events per second for real-time analysis and monitoring.

16. Describe partitioning key in Kafka.

    In Kafka, a partitioning key is a field or attribute present in the message that is used to determine the partition to which the message will be assigned. When a message is produced to a Kafka topic, the producer can specify a partitioning key along with the message payload. The partitioning key is used by Kafka's partitioning mechanism to determine the partition to which the message will be assigned.

17. What is the purpose of partitions in Kafka?

    The partitioning key serves two main purposes:

    1. Determining the Partition: Kafka uses a partitioning algorithm to determine the target partition based on the partitioning key. This ensures that messages with the same partitioning key are always assigned to the same partition, providing a way to guarantee message ordering within a partition.
    2. Load Balancing: By distributing messages across multiple partitions based on the partitioning key, Kafka achieves load balancing. Messages with different partitioning keys are evenly distributed across partitions, allowing for parallel processing and high throughput.

    The choice of a partitioning key depends on the use case and requirements. It is often selected based on a field that allows for efficient distribution and grouping of related messages, such as a user ID, device ID, or geographic region. Care should be taken to choose a key that provides good distribution to avoid potential hotspots and ensure optimal performance and scalability in a Kafka cluster.

18. Differentiate between Rabbitmq and Kafka.

    1. Messaging Model:
       - RabbitMQ: RabbitMQ follows the traditional message broker model based on the Advanced Message Queuing Protocol (AMQP). It focuses on reliable message delivery and supports various messaging patterns like point-to-point, publish-subscribe, and request-reply.
       - Kafka: Kafka is designed as a distributed streaming platform. It is based on the publish-subscribe model and allows high-throughput, fault-tolerant, and scalable streaming of records. Kafka is optimized for handling large volumes of data streams.

    2. Persistence:
       - RabbitMQ: RabbitMQ persists messages on disk, ensuring reliable message storage even in the event of a system failure.
       - Kafka: Kafka uses a distributed commit log architecture and persists messages on disk as immutable logs. This design allows for high-performance and fault-tolerant data replication.

    3. Scalability and Throughput:
       - RabbitMQ: RabbitMQ is well-suited for handling moderate workloads and supports horizontal scaling by adding more broker nodes to a cluster.
       - Kafka: Kafka is built for high scalability and can handle massive data streams with high throughput. It is designed to be distributed and can scale horizontally across multiple brokers.

    4. Message Retention:
       - RabbitMQ: RabbitMQ retains messages as long as they are needed by consumers or until they expire based on configurable policies.
       - Kafka: Kafka retains messages for a configurable period of time, allowing consumers to replay messages within a specific time window.

    5. Use Cases:
       - RabbitMQ: RabbitMQ is commonly used in applications that require reliable message delivery and decoupling of components, such as traditional enterprise messaging, task queues, and RPC.
       - Kafka: Kafka is well-suited for real-time data streaming, event sourcing, log aggregation, metrics collection, and building streaming data pipelines.

19. What are the guarantees that Kafka provides?

    Publish-Subscribe Model, Fast Async Response, Scalability and High Throughput;Fault-Tolerance and Durability

20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?

    An unbalanced cluster in Kafka refers to a situation where the distribution of partitions across brokers is uneven. This means that some brokers may be handling a significantly higher load than others, which can lead to performance issues and potential bottlenecks.

    To balance an unbalanced cluster in Kafka:

    1. Monitor Cluster: Use monitoring tools to identify the brokers and partitions that are experiencing high load or uneven distribution.

    2. Reassign Partitions: Use the Kafka partition reassignment feature to manually or automatically redistribute partitions across brokers. This can be done using the `kafka-reassign-partitions.sh` tool or by modifying the partition assignment strategy.

    3. Add or Remove Brokers: If necessary, add more brokers to the cluster or remove brokers to adjust the distribution of partitions. This can be done by scaling up or down the number of Kafka broker instances.

    4. Adjust Partition Assignment Strategy: Modify the partition assignment strategy to ensure a more even distribution of partitions across brokers. Kafka provides different strategies such as the default `Range` strategy or the `RoundRobin` strategy.

    5. Consider Hardware Resources: Take into account the hardware resources of each broker when balancing the cluster. Ensure that brokers have similar processing power, memory, disk storage, and network capacity.

    6. Monitor and Fine-tune: Continuously monitor the cluster and adjust the partition assignment as needed to maintain a balanced and efficient state.

21. In your recent project, are you a producer or consumer or both?

    这几个问题是不是要等final project完成了再来回答？

22. In your recent project, Could you tell me your topic name?

23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.

24. In your recent project, which team produce what kind of event to you and you producer what kind of events?

25. What is offset?

    In Kafka, an offset represents the unique identifier of a specific message within a partition of a topic. It is a sequential number assigned to each message as it is produced to the Kafka cluster. 

    Offsets are used to track the progress of consumers within a topic. Each consumer maintains its own offset, indicating the last message it has consumed from a partition. This allows consumers to continue reading from where they left off in case of failures or when new consumers join the group.

    Offsets have the following characteristics:
    - Offsets are maintained by Kafka and are persisted along with the messages on the broker.
    - Offsets are ordered and monotonically increasing within a partition.
    - Offsets are committed by consumers to indicate that a message has been successfully processed.
    - Consumers can specify the offset from which they want to start consuming messages.

    By using offsets, Kafka enables efficient and fault-tolerant message processing across multiple consumers and provides flexibility in managing the consumption progress within a topic.